{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator #, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "# from tensorflow.keras.convolutional import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELF_PATH = os.getcwd()\n",
    "PATH_TO_FILE_STREAM = 'G:\\\\Shared drives\\\\P-Sick'\n",
    "PATH_TO_IMAGES = os.path.join(PATH_TO_FILE_STREAM, 'small\\\\Florence\\\\20180917a_jpgs\\\\jpgs')\n",
    "PATH_TO_TAG_CSV = os.path.join(SELF_PATH, '../tagging_data.csv')\n",
    "\n",
    "TEST_TO_TRAIN_RATIO = 0.3\n",
    "\n",
    "TRAINING_IMAGE_FOLDER = \"../_training_images\"\n",
    "TESTING_IMAGE_FOLDER = \"../_testing_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "These are a list of the ids for impact\n",
    "```\n",
    "NoneId:0  \n",
    "SwashId:1  \n",
    "CollisionId:2  \n",
    "OverwashId:3  \n",
    "InundationId:4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the images\n",
    "\n",
    "1. We need to load the data from the csv\n",
    "2. Split the images up into training and test set, and then place them in seperate folders."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "First lets load the csv that has all the completely tagged image tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image_tags = pd.read_csv(PATH_TO_TAG_CSV)\n",
    "df_impact_images = df_image_tags[['image_id','impact']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>impact</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>195</th>\n      <td>P26059362.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>P26056609.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>P26056111.jpg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>P26048120.jpg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>P26056256.jpg</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "          image_id  impact\n195  P26059362.jpg       1\n122  P26056609.jpg       3\n24   P26056111.jpg       3\n108  P26048120.jpg       0\n80   P26056256.jpg       2"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_images, df_testing_images = train_test_split(df_impact_images, test_size=TEST_TO_TRAIN_RATIO, random_state=420)\n",
    "df_testing_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Before we copy the images, remove all files within these folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(TRAINING_IMAGE_FOLDER):\n",
    "    os.remove(os.path.join(TRAINING_IMAGE_FOLDER,file)) \n",
    "\n",
    "for file in os.listdir(TESTING_IMAGE_FOLDER):\n",
    "    os.remove(os.path.join(TESTING_IMAGE_FOLDER,file)) "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Copy our training and test images into their respective folders, while keeping metadata with copy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Moved training and test images to their respective folders\n"
    }
   ],
   "source": [
    "for image in df_testing_images['image_id']:\n",
    "    shutil.copy2(os.path.join(PATH_TO_IMAGES,image),  os.path.join(TRAINING_IMAGE_FOLDER,image))\n",
    "\n",
    "for image in df_testing_images['image_id']:\n",
    "    shutil.copy2(os.path.join(PATH_TO_IMAGES,image),  os.path.join(TESTING_IMAGE_FOLDER,image))\n",
    "\n",
    "print(\"Moved training and test images to their respective folders\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the images\n",
    "\n",
    "1. For the training df, seperate the `image_id` and the `impact` into different np arrays for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_samples = np.array(range(0,len(df_training_images['impact'])))#df_impact_images['image_id'].to_numpy()\n",
    "image_labels = df_training_images['impact'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16,input_shape = (1,),activation = 'relu'),\n",
    "    Dense(32,activation = 'relu'),\n",
    "    Dense(5, activation= 'softmax') # that five has to be same as number of classes\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 121 samples, validate on 52 samples\nEpoch 1/5\n121/121 - 0s - loss: 8.2012 - accuracy: 0.2562 - val_loss: 23.8097 - val_accuracy: 0.0962\nEpoch 2/5\n121/121 - 0s - loss: 7.3669 - accuracy: 0.2562 - val_loss: 21.2493 - val_accuracy: 0.0962\nEpoch 3/5\n121/121 - 0s - loss: 6.5535 - accuracy: 0.2562 - val_loss: 18.5886 - val_accuracy: 0.0962\nEpoch 4/5\n121/121 - 0s - loss: 5.7964 - accuracy: 0.2562 - val_loss: 15.9653 - val_accuracy: 0.0962\nEpoch 5/5\n121/121 - 0s - loss: 5.0643 - accuracy: 0.2562 - val_loss: 13.5220 - val_accuracy: 0.0962\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2d7ddbb8668>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.0001),loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(image_samples,image_labels,batch_size = 5, epochs = 5, shuffle = True, verbose = 2, validation_split= TEST_TO_TRAIN_RATIO )"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D:"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "173/1 - 0s\n"
    }
   ],
   "source": [
    "test_labels = np.array(range(0,len(df_training_images['impact'])))\n",
    "predictions = model.predict(test_labels,batch_size= 5, verbose= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0.20356572 0.19951431 0.20196655 0.1952965  0.1996569 ]\n[0.19356059 0.20665938 0.19735663 0.20239978 0.2000237 ]\n[0.1823911  0.21323806 0.19124639 0.21257997 0.20054445]\n[0.17159909 0.21968426 0.18503731 0.22292523 0.20075409]\n[0.16119759 0.22597758 0.17875478 0.23341475 0.2006552 ]\n"
    }
   ],
   "source": [
    "for i in predictions[:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "173/1 - 0s\n0\n1\n1\n3\n3\n"
    }
   ],
   "source": [
    "\n",
    "predictions_rounded = model.predict_classes(test_labels,batch_size= 5, verbose= 2)\n",
    "for i in predictions_rounded[:5]:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}